{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T06:30:36.434098Z",
     "iopub.status.busy": "2023-01-22T06:30:36.433638Z",
     "iopub.status.idle": "2023-01-22T06:30:36.447209Z",
     "shell.execute_reply": "2023-01-22T06:30:36.445746Z",
     "shell.execute_reply.started": "2023-01-22T06:30:36.434053Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as bknd\n",
    "from keras.callbacks import *\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import *\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "#from stn import spatial_transformer_network as transformer\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten,concatenate \n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras,os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T06:43:15.954018Z",
     "iopub.status.busy": "2023-01-22T06:43:15.953663Z",
     "iopub.status.idle": "2023-01-22T06:51:23.527425Z",
     "shell.execute_reply": "2023-01-22T06:51:23.526567Z",
     "shell.execute_reply.started": "2023-01-22T06:43:15.953985Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loc = 'CWT\\\\train_4000'\n",
    "test_loc = 'CWT\\\\clean\\\\test'\n",
    "inputShape = Input((224,224, 3))  # base on Tensorflow backend\n",
    "conv_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputShape)\n",
    "x_inputi = BatchNormalization()(conv_1)\n",
    "conv_2 = Conv2D(64, (3, 3), activation='relu', padding='same')(x_inputi)\n",
    "conv_3 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv_2)\n",
    "batchnorm_3 = BatchNormalization()(conv_3)\n",
    "x_inputi= MaxPooling2D(pool_size=(2, 2))(batchnorm_3)\n",
    "conv_4 = Conv2D(64, (3, 3), activation='relu', padding='same')(x_inputi)\n",
    "conv_5 = Conv2D(96, (5, 5), activation='relu', padding='same')(conv_4)\n",
    "batchnorm_5 = BatchNormalization()(conv_5)\n",
    "x_inputi= MaxPooling2D(pool_size=(2, 2))(batchnorm_5)\n",
    "x_in1i = Conv2D(filters = int(x_inputi.shape[-1]//4), kernel_size = (1,1), strides = (1,1), padding = 'valid', activation = 'relu')(x_inputi)\n",
    "x_in1i=BatchNormalization()(x_in1i)\n",
    "x_in2i = Conv2D(filters = int(x_inputi.shape[-1]//2), kernel_size = (1,1), strides = (1,1), padding = 'valid', activation = 'relu')(x_in1i)\n",
    "x_in2i=BatchNormalization()(x_in2i)\n",
    "x_in3i = Conv2D(filters = int(x_inputi.shape[-1]//2), kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')(x_in1i)\n",
    "x_in3i=BatchNormalization()(x_in3i)\n",
    "out = Concatenate() ([x_in2i, x_in3i])\n",
    "conv_6 = Conv2D(96, (5, 5), activation='relu', padding='same')(out)\n",
    "conv_7 = Conv2D(96, (5, 5), activation='relu', padding='same')(conv_6)\n",
    "batchnorm_7 = BatchNormalization()(conv_7)\n",
    "#pool_5 = MaxPooling2D(pool_size=(2, 2))(batchnorm_7)\n",
    "bn_shape = batchnorm_7.get_shape()\n",
    "print(bn_shape)  # (?, 50, 7, 512)\n",
    "\n",
    "# reshape to (batch_size, width, height*dim)\n",
    "# x_reshape = Reshape(target_shape=(int(bn_shape[1]), int(bn_shape[2] * bn_shape[3])))(stn_7)\n",
    "x_reshape = Reshape(target_shape=(int(bn_shape[1]), int(bn_shape[2] * bn_shape[3])))(batchnorm_7)\n",
    "\n",
    "fc_1 = Dense(128, activation='relu')(x_reshape)  # (?, 50, 128)\n",
    "\n",
    "print(x_reshape.get_shape())  # (?, 50, 3584)\n",
    "print(fc_1.get_shape())  # (?, 50, 128)\n",
    "\n",
    "rnn_1 = LSTM(32, kernel_initializer=\"he_normal\", return_sequences=True)(fc_1)\n",
    "rnn_1b = LSTM(32, kernel_initializer=\"he_normal\", go_backwards=True, return_sequences=True)(fc_1)\n",
    "rnn1_merged = add([rnn_1, rnn_1b])\n",
    "\n",
    "rnn_2 = LSTM(32, kernel_initializer=\"he_normal\", return_sequences=True)(rnn1_merged)\n",
    "rnn_2b = LSTM(32, kernel_initializer=\"he_normal\", go_backwards=True, return_sequences=True)(rnn1_merged)\n",
    "rnn2_merged = concatenate([rnn_2, rnn_2b])\n",
    "\n",
    "drop_1 = Dropout(0.25)(rnn2_merged)\n",
    "classifier=Flatten()(drop_1)\n",
    "#fc_2 = Dense(512, kernel_initializer='he_normal', activation='relu')(classifier)\n",
    "fc_2 = Dense(256, kernel_initializer='he_normal', activation='relu')(classifier)\n",
    "fc_2 = Dense(128, kernel_initializer='he_normal', activation='relu')(classifier)\n",
    "fc_2 = Dense(64, kernel_initializer='he_normal', activation='relu')(fc_2)\n",
    "fc_2 = Dense(32, kernel_initializer='he_normal', activation='relu')(fc_2)\n",
    "fc_2 = Dense(16, kernel_initializer='he_normal', activation='relu')(fc_2)\n",
    "fc_2 = Dense(5, kernel_initializer='he_normal', activation='softmax')(fc_2)\n",
    "\n",
    "# model setting\n",
    "base_model = Model(inputs=inputShape, outputs=fc_2) \n",
    "adam = keras.optimizers.Adam(lr = 0.0001)\n",
    "base_model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "trdata = ImageDataGenerator(rescale=1./255)\n",
    "traindata = trdata.flow_from_directory(directory=train_loc, target_size=(224,224),batch_size=16)\n",
    "tsdata = ImageDataGenerator(rescale=1./255)\n",
    "testdata = tsdata.flow_from_directory(directory=test_loc, target_size=(224,224),batch_size=16)\n",
    "\n",
    "\n",
    "filepath=\"CWT//cwt_weights//model_0_cwt_v2_awgn_trial.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)\n",
    "callbacks_list = [checkpoint,es]\n",
    "base_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),loss=keras.losses.categorical_crossentropy,metrics=['accuracy'])\n",
    "hist = base_model.fit_generator(epochs=60,generator=traindata,validation_data=testdata,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"CWT//cwt_weights//model_0_cwt_v2_awgn_trial.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisDF=pd.DataFrame(hist.history)\n",
    "hisDF.to_csv('CWT//history_model_0_cwt_v2_trial.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
